{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Apparel Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4.2] Data and Code:\n",
    "(https://drive.google.com/open?id=0BwNkduBnePt2VWhCYXhMV3p4dTg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4.3] Overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/plain": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "#import seaborn as sns\n",
    "from collections import Counter\n",
    "'''from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from sklearn.metrics import pairwise_distances'''\n",
    "from matplotlib import gridspec\n",
    "from scipy.sparse import hstack\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "#from plotly.graph_objs import Scatter, Layout\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have give a json file which consists of all information about\n",
    "# the products\n",
    "# loading the data using pandas' read_json file.\n",
    "'''import os\n",
    "print(os.getcwd())'''\n",
    "#the above code is to check which directory i am in\n",
    "data = pd.read_json(open('/Users\\DELL\\PythonProjects\\RECOMENDATION_ENGINE/tops_fashion.json', \"r\", encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points :  183138\nNumber of features/variables: 19\n"
     ]
    }
   ],
   "source": [
    "print ('Number of data points : ', data.shape[0])\n",
    "print ('Number of features/variables:', data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology:\n",
    "What is a dataset? <br>\n",
    "Rows and columns <br>\n",
    "Data-point <br>\n",
    "Feature/variable <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['asin', 'author', 'availability', 'availability_type', 'brand', 'color',\n       'editorial_reivew', 'editorial_review', 'formatted_price',\n       'large_image_url', 'manufacturer', 'medium_image_url', 'model',\n       'product_type_name', 'publisher', 'reviews', 'sku', 'small_image_url',\n       'title'],\n      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each product/item has 19 features in the raw dataset.\n",
    "data.columns # prints column-names or feature-names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['asin', 'brand', 'color', 'medium_image_url', 'product_type_name', 'title', 'formatted_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points :  183138 Number of features: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B016I2TS4W</td>\n",
       "      <td>FNC7C</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Minions Como Superheroes Ironman Long Sleeve R...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B01N49AI08</td>\n",
       "      <td>FIG Clothing</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>FIG Clothing Womens Izo Tunic</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B01JDPCOHO</td>\n",
       "      <td>FIG Clothing</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>FIG Clothing Womens Won Top</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B01N19U5H5</td>\n",
       "      <td>Focal18</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Focal18 Sailor Collar Bubble Sleeve Blouse Shi...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004GSI2OS</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>Onyx Black/ Stone</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Featherlite Ladies' Long Sleeve Stain Resistan...</td>\n",
       "      <td>$26.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B016I2TS4W</td>\n",
       "      <td>FNC7C</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Minions Como Superheroes Ironman Long Sleeve R...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B01N49AI08</td>\n",
       "      <td>FIG Clothing</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>FIG Clothing Womens Izo Tunic</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B01JDPCOHO</td>\n",
       "      <td>FIG Clothing</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>FIG Clothing Womens Won Top</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B01N19U5H5</td>\n",
       "      <td>Focal18</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Focal18 Sailor Collar Bubble Sleeve Blouse Shi...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004GSI2OS</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>Onyx Black/ Stone</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Featherlite Ladies' Long Sleeve Stain Resistan...</td>\n",
       "      <td>$26.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Number of data points : ', data.shape[0], \\\n",
    "       'Number of features:', data.shape[1])\n",
    "data.head() # prints the top rows in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.1] Missing data for various features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Basic stats for the feature: product_type_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     183138\nunique        72\ntop        SHIRT\nfreq      167794\nName: product_type_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# We have total 72 unique type of product_type_names\n",
    "print(data['product_type_name'].describe())\n",
    "\n",
    "# 91.62% (167794/183138) of the products are shirts,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SHIRT' 'SWEATER' 'APPAREL' 'OUTDOOR_RECREATION_PRODUCT'\n 'BOOKS_1973_AND_LATER' 'PANTS' 'HAT' 'SPORTING_GOODS' 'DRESS' 'UNDERWEAR'\n 'SKIRT' 'OUTERWEAR' 'BRA' 'ACCESSORY' 'ART_SUPPLIES' 'SLEEPWEAR'\n 'ORCA_SHIRT' 'HANDBAG' 'PET_SUPPLIES' 'SHOES' 'KITCHEN' 'ADULT_COSTUME'\n 'HOME_BED_AND_BATH' 'MISC_OTHER' 'BLAZER' 'HEALTH_PERSONAL_CARE'\n 'TOYS_AND_GAMES' 'SWIMWEAR' 'CONSUMER_ELECTRONICS' 'SHORTS' 'HOME'\n 'AUTO_PART' 'OFFICE_PRODUCTS' 'ETHNIC_WEAR' 'BEAUTY'\n 'INSTRUMENT_PARTS_AND_ACCESSORIES' 'POWERSPORTS_PROTECTIVE_GEAR' 'SHIRTS'\n 'ABIS_APPAREL' 'AUTO_ACCESSORY' 'NONAPPARELMISC' 'TOOLS' 'BABY_PRODUCT'\n 'SOCKSHOSIERY' 'POWERSPORTS_RIDING_SHIRT' 'EYEWEAR' 'SUIT'\n 'OUTDOOR_LIVING' 'POWERSPORTS_RIDING_JACKET' 'HARDWARE' 'SAFETY_SUPPLY'\n 'ABIS_DVD' 'VIDEO_DVD' 'GOLF_CLUB' 'MUSIC_POPULAR_VINYL'\n 'HOME_FURNITURE_AND_DECOR' 'TABLET_COMPUTER' 'GUILD_ACCESSORIES'\n 'ABIS_SPORTS' 'ART_AND_CRAFT_SUPPLY' 'BAG' 'MECHANICAL_COMPONENTS'\n 'SOUND_AND_RECORDING_EQUIPMENT' 'COMPUTER_COMPONENT' 'JEWELRY'\n 'BUILDING_MATERIAL' 'LUGGAGE' 'BABY_COSTUME' 'POWERSPORTS_VEHICLE_PART'\n 'PROFESSIONAL_HEALTHCARE' 'SEEDS_AND_PLANTS' 'WIRELESS_ACCESSORY']\n"
     ]
    }
   ],
   "source": [
    "# names of different product types\n",
    "print(data['product_type_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SHIRT', 167794),\n ('APPAREL', 3549),\n ('BOOKS_1973_AND_LATER', 3336),\n ('DRESS', 1584),\n ('SPORTING_GOODS', 1281),\n ('SWEATER', 837),\n ('OUTERWEAR', 796),\n ('OUTDOOR_RECREATION_PRODUCT', 729),\n ('ACCESSORY', 636),\n ('UNDERWEAR', 425)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the 10 most frequent product_type_names.\n",
    "product_type_count = Counter(list(data['product_type_name']))\n",
    "product_type_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Basic stats for the feature: brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     182987\nunique     10577\ntop         Zago\nfreq         223\nName: brand, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# there are 10577 unique brands\n",
    "print(data['brand'].describe())\n",
    "\n",
    "# 183138 - 182987 = 151 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zago', 223),\n ('XQS', 222),\n ('Yayun', 215),\n ('YUNY', 198),\n ('XiaoTianXin-women clothes', 193),\n ('Generic', 192),\n ('Boohoo', 190),\n ('Alion', 188),\n ('Abetteric', 187),\n ('TheMogan', 187)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_count = Counter(list(data['brand']))\n",
    "brand_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Basic stats for the feature: color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     64956\nunique     7380\ntop       Black\nfreq      13207\nName: color, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['color'].describe())\n",
    "\n",
    "\n",
    "# we have 7380 unique colors\n",
    "# 7.2% of products are black in color\n",
    "# 64956 of 183138 products have brand information. That's approx 35.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 118182),\n ('Black', 13207),\n ('White', 8616),\n ('Blue', 3570),\n ('Red', 2289),\n ('Pink', 1842),\n ('Grey', 1499),\n ('*', 1388),\n ('Green', 1258),\n ('Multi', 1203)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_count = Counter(list(data['color']))\n",
    "color_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Basic stats for the feature: formatted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      28395\nunique      3135\ntop       $19.99\nfreq         945\nName: formatted_price, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['formatted_price'].describe())\n",
    "\n",
    "# Only 28,395 (15.5% of whole data) products with price information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 154743),\n ('$19.99', 945),\n ('$9.99', 749),\n ('$9.50', 601),\n ('$14.99', 472),\n ('$7.50', 463),\n ('$24.99', 414),\n ('$29.99', 370),\n ('$8.99', 343),\n ('$9.01', 336)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_count = Counter(list(data['formatted_price']))\n",
    "price_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic stats for the feature: title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                                                183138\nunique                                               175985\ntop       Nakoda Cotton Self Print Straight Kurti For Women\nfreq                                                     77\nName: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['title'].describe())\n",
    "\n",
    "# All of the products have a title. \n",
    "# Titles are fairly descriptive of what the product is. \n",
    "# We use titles extensively in this workshop \n",
    "# as they are short and informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('pickels/180k_apparel_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   We save data files at every major step in our processing in \"pickle\" files. If you are stuck anywhere (or) if some code takes too long to run on your laptop, you may use the pickle files we give you to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points After eliminating price=NULL : 28395\n"
     ]
    }
   ],
   "source": [
    "# consider products which have price information\n",
    "# data['formatted_price'].isnull() => gives the information \n",
    "#about the dataframe row's which have null values price == None|Null\n",
    "data = data.loc[~data['formatted_price'].isnull()]\n",
    "print('Number of data points After eliminating price=NULL :', data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We brought down the number of data points from 183K  to 28K.\n",
    "\n",
    "We are processing only 28K points so that most of the workshop participants can run this code on thier laptops in a reasonable amount of time. <br> \n",
    "\n",
    "For those of you who have powerful computers and some time to spare, you are recommended to use all of the 183K images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('pickels/180k_apparel_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom PIL import Image\\nimport requests\\nfrom io import BytesIO\\n\\nfor index, row in images.iterrows():\\n        url = row['large_image_url']\\n        response = requests.get(url)\\n        img = Image.open(BytesIO(response.content))\\n        img.save('images/28k_images/'+row['asin']+'.jpeg')\\n\\n\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can download all these 28k images using this code below.\n",
    "# You do NOT need to run this code and hence it is commented.\n",
    "\n",
    "\n",
    "'''\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "for index, row in images.iterrows():\n",
    "        url = row['large_image_url']\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save('images/28k_images/'+row['asin']+'.jpeg')\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2] Remove near duplicate items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [5.2.1] Understand about duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2326\n"
     ]
    }
   ],
   "source": [
    "# read data from pickle file from previous stage\n",
    "data = pd.read_pickle('pickels/180k_apparel_data')\n",
    "\n",
    "# find number of products that have duplicate titles.\n",
    "print(sum(data.duplicated('title')))\n",
    "# we have 2325 products which have same title but different color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These shirts are exactly same except in size (S, M,L,XL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr> \n",
    "<td><img src=\"dedupe/B00AQ4GMCK.jpeg\",width=100,height=100> :B00AQ4GMCK</td>\n",
    "<td><img src=\"dedupe/B00AQ4GMTS.jpeg\",width=100,height=100> :B00AQ4GMTS</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td><img src=\"dedupe/B00AQ4GMLQ.jpeg\",width=100,height=100> :B00AQ4GMLQ</td>\n",
    "<td><img src=\"dedupe/B00AQ4GN3I.jpeg\",width=100,height=100> :B00AQ4GN3I</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These shirts exactly same except  in color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr> \n",
    "<td><img src=\"dedupe/B00G278GZ6.jpeg\",width=100,height=100> :B00G278GZ6</td>\n",
    "<td><img src=\"dedupe/B00G278W6O.jpeg\",width=100,height=100> :B00G278W6O</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td><img src=\"dedupe/B00G278Z2A.jpeg\",width=100,height=100> :B00G278Z2A</td>\n",
    "<td><img src=\"dedupe/B00G2786X8.jpeg\",width=100,height=100> :B00G2786X8</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In our data there are many duplicate products like the above examples, we need to de-dupe them for better results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [5.2.2] Remove duplicates : Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from pickle file from previous stage\n",
    "data = pd.read_pickle('pickels/180k_apparel_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004GSI2OS</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>Onyx Black/ Stone</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Featherlite Ladies' Long Sleeve Stain Resistan...</td>\n",
       "      <td>$26.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B012YX2ZPI</td>\n",
       "      <td>HX-Kingdom Fashion T-shirts</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Women's Unique 100% Cotton T - Special Olympic...</td>\n",
       "      <td>$9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B001LOUGE4</td>\n",
       "      <td>Fitness Etc.</td>\n",
       "      <td>Black</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Ladies Cotton Tank 2x1 Ribbed Tank Top</td>\n",
       "      <td>$11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B003BSRPB0</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>FeatherLite Ladies' Moisture Free Mesh Sport S...</td>\n",
       "      <td>$20.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B014ICEDNA</td>\n",
       "      <td>FNC7C</td>\n",
       "      <td>Purple</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Supernatural Chibis Sam Dean And Castiel Short...</td>\n",
       "      <td>$7.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004GSI2OS</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>Onyx Black/ Stone</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Featherlite Ladies' Long Sleeve Stain Resistan...</td>\n",
       "      <td>$26.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B012YX2ZPI</td>\n",
       "      <td>HX-Kingdom Fashion T-shirts</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Women's Unique 100% Cotton T - Special Olympic...</td>\n",
       "      <td>$9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B001LOUGE4</td>\n",
       "      <td>Fitness Etc.</td>\n",
       "      <td>Black</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Ladies Cotton Tank 2x1 Ribbed Tank Top</td>\n",
       "      <td>$11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B003BSRPB0</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>FeatherLite Ladies' Moisture Free Mesh Sport S...</td>\n",
       "      <td>$20.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B014ICEDNA</td>\n",
       "      <td>FNC7C</td>\n",
       "      <td>Purple</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Supernatural Chibis Sam Dean And Castiel Short...</td>\n",
       "      <td>$7.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removal of products with short description: 27958\n"
     ]
    }
   ],
   "source": [
    "# Remove All products with very few words in title\n",
    "data_sorted = data[data['title'].apply(lambda x: len(x.split())>4)]\n",
    "print(\"After removal of products with short description:\", data_sorted.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61973</th>\n",
       "      <td>B06Y1KZ2WB</td>\n",
       "      <td>Éclair</td>\n",
       "      <td>Black/Pink</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Éclair Women's Printed Thin Strap Blouse Black...</td>\n",
       "      <td>$24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133820</th>\n",
       "      <td>B010RV33VE</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>Pink</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Womens Sleeveless Loose Long T-shirts...</td>\n",
       "      <td>$18.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81461</th>\n",
       "      <td>B01DDSDLNS</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Women's White Long Sleeve Single Brea...</td>\n",
       "      <td>$21.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75995</th>\n",
       "      <td>B00X5LYO9Y</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>Red Anchors</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Stripes Tank Patch/Bear Sleeve Anchor...</td>\n",
       "      <td>$15.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151570</th>\n",
       "      <td>B00WPJG35K</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Sleeve Sheer Loose Tassel Kimono Woma...</td>\n",
       "      <td>$14.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61973</th>\n",
       "      <td>B06Y1KZ2WB</td>\n",
       "      <td>Éclair</td>\n",
       "      <td>Black/Pink</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>Éclair Women's Printed Thin Strap Blouse Black...</td>\n",
       "      <td>$24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133820</th>\n",
       "      <td>B010RV33VE</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>Pink</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Womens Sleeveless Loose Long T-shirts...</td>\n",
       "      <td>$18.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81461</th>\n",
       "      <td>B01DDSDLNS</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Women's White Long Sleeve Single Brea...</td>\n",
       "      <td>$21.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75995</th>\n",
       "      <td>B00X5LYO9Y</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>Red Anchors</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Stripes Tank Patch/Bear Sleeve Anchor...</td>\n",
       "      <td>$15.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151570</th>\n",
       "      <td>B00WPJG35K</td>\n",
       "      <td>xiaoming</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>xiaoming Sleeve Sheer Loose Tassel Kimono Woma...</td>\n",
       "      <td>$14.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the whole data based on title (alphabetical order of title) \n",
    "data_sorted.sort_values('title',inplace=True, ascending=False)\n",
    "data_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some examples of dupliacte titles that differ only in the last few words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i,row in data_sorted.iterrows():\n",
    "    indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "stage1_dedupe_asins = []\n",
    "i = 0\n",
    "j = 0\n",
    "num_data_points = data_sorted.shape[0]\n",
    "while i < num_data_points and j < num_data_points:\n",
    "    \n",
    "    previous_i = i\n",
    "\n",
    "    # store the list of words of ith string in a, ex: a = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'X-Large']\n",
    "    a = data['title'].loc[indices[i]].split()\n",
    "\n",
    "    # search for the similar products sequentially \n",
    "    j = i+1\n",
    "    while j < num_data_points:\n",
    "\n",
    "        # store the list of words of jth string in b, ex: b = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'Small']\n",
    "        b = data['title'].loc[indices[j]].split()\n",
    "\n",
    "        # store the maximum length of two strings\n",
    "        length = max(len(a), len(b))\n",
    "\n",
    "        # count is used to store the number of words that are matched in both strings\n",
    "        count  = 0\n",
    "\n",
    "        # itertools.zip_longest(a,b): will map the corresponding words in both strings, it will appened None in case of unequal strings\n",
    "        # example: a =['a', 'b', 'c', 'd']\n",
    "        # b = ['a', 'b', 'd']\n",
    "        # itertools.zip_longest(a,b): will give [('a','a'), ('b','b'), ('c','d'), ('d', None)]\n",
    "        for k in itertools.zip_longest(a,b): \n",
    "            if (k[0] == k[1]):\n",
    "                count += 1\n",
    "\n",
    "        # if the number of words in which both strings differ are > 2 , we are considering it as those two apperals are different\n",
    "        # if the number of words in which both strings differ are < 2 , we are considering it as those two apperals are same, hence we are ignoring them\n",
    "        if (length - count) > 2: # number of words in which both sensences differ\n",
    "            # if both strings are differ by more than 2 words we include the 1st string index\n",
    "            stage1_dedupe_asins.append(data_sorted['asin'].loc[indices[i]])\n",
    "\n",
    "            # if the comaprision between is between num_data_points, num_data_points-1 strings and they differ in more than 2 words we include both\n",
    "            if j == num_data_points-1: stage1_dedupe_asins.append(data_sorted['asin'].loc[indices[j]])\n",
    "\n",
    "            # start searching for similar apperals corresponds 2nd string\n",
    "            i = j\n",
    "            break\n",
    "        else:\n",
    "            j += 1\n",
    "    if previous_i == i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['asin'].isin(stage1_dedupe_asins)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We removed  the dupliactes which differ only at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points :  17597\n"
     ]
    }
   ],
   "source": [
    "print('Number of data points : ', data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('pickels/17k_apperal_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [5.2.3] Remove duplicates : Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('pickels/17k_apperal_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-35-28de7efad93f>\", line 16, in <module>\n    for j in indices:\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2018, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n    return f(*args, **kwargs)\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 347, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\inspect.py\", line 1500, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\inspect.py\", line 1458, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n    if ismodule(module) and hasattr(module, '__file__'):\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 195, in __getattribute__\n    return getattr(getmod(), name)\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 179, in getmod\n    x = importobj(modpath, None)\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 69, in importobj\n    module = __import__(modpath, None, None, ['__doc__'])\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pytest.py\", line 8, in <module>\n    from _pytest.config import cmdline\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\_pytest\\config\\__init__.py\", line 25, in <module>\n    from .exceptions import PrintHelp\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n  File \"<frozen importlib._bootstrap_external>\", line 818, in get_code\n  File \"<frozen importlib._bootstrap_external>\", line 917, in get_data\nKeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# This code snippet takes significant amount of time.\n",
    "# O(n^2) time.\n",
    "# Takes about an hour to run on a decent computer.\n",
    "\n",
    "indices = []\n",
    "for i,row in data.iterrows():\n",
    "    indices.append(i)\n",
    "\n",
    "stage2_dedupe_asins = []\n",
    "while len(indices)!=0:\n",
    "    i = indices.pop()\n",
    "    stage2_dedupe_asins.append(data['asin'].loc[i])\n",
    "    # consider the first apperal's title\n",
    "    a = data['title'].loc[i].split()\n",
    "    # store the list of words of ith string in a, ex: a = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'X-Large']\n",
    "    for j in indices:\n",
    "        \n",
    "        b = data['title'].loc[j].split()\n",
    "        # store the list of words of jth string in b, ex: b = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'X-Large']\n",
    "        \n",
    "        length = max(len(a),len(a))\n",
    "        \n",
    "        # count is used to store the number of words that are matched in both strings\n",
    "        count  = 0\n",
    "\n",
    "        # itertools.zip_longest(a,b): will map the corresponding words in both strings, it will appened None in case of unequal strings\n",
    "        # example: a =['a', 'b', 'c', 'd']\n",
    "        # b = ['a', 'b', 'd']\n",
    "        # itertools.zip_longest(a,b): will give [('a','a'), ('b','b'), ('c','d'), ('d', None)]\n",
    "        for k in itertools.zip_longest(a,b): \n",
    "            if (k[0]==k[1]):\n",
    "                count += 1\n",
    "\n",
    "        # if the number of words in which both strings differ are < 3 , we are considering it as those two apperals are same, hence we are ignoring them\n",
    "        if (length - count) < 3:\n",
    "            indices.remove(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from whole previous products we will consider only \n",
    "# the products that are found in previous cell \n",
    "data = data.loc[data['asin'].isin(stage2_dedupe_asins)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points after stage two of dedupe:  39\n"
     ]
    }
   ],
   "source": [
    "print('Number of data points after stage two of dedupe: ',data.shape[0])\n",
    "# from 17k apperals we reduced to 16k apperals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('pickels/16k_apperal_data')\n",
    "# Storing these products in a pickle file\n",
    "# candidates who wants to download these files instead \n",
    "# of 180K they can download and use them from the Google Drive folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('pickels/16k_apperal_data')\n",
    "\n",
    "# NLTK download stop words. [RUN ONLY ONCE]\n",
    "# goto Terminal (Linux/Mac) or Command-Prompt (Window) \n",
    "# In the temrinal, type these commands\n",
    "# $python3\n",
    "# $import nltk\n",
    "# $nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of stop words: {'re', 'nor', 'through', 'be', 'hadn', 'ourselves', 'few', 'now', 'being', 's', 'once', 'are', \"she's\", 'd', 'because', 'him', \"isn't\", 'its', 'each', 'during', 'their', \"wasn't\", 'against', 'm', \"mustn't\", 'did', \"shouldn't\", 'by', 'should', 'wasn', 'i', 'over', 'my', 'again', 'if', 'needn', \"should've\", 'while', 'himself', 'a', 'not', 'our', 'does', 'until', 'me', 'to', 'all', \"don't\", 'had', 't', 'why', \"weren't\", 'itself', 'then', 'theirs', 'shouldn', 'an', 'there', 'myself', 'for', 'or', 'didn', \"that'll\", \"hadn't\", 'the', 'were', \"aren't\", 'o', 'ma', 'shan', \"won't\", 'his', 'here', 'aren', 'off', 'from', 'she', 'up', 'as', 'between', 'where', 'whom', 'most', 'll', 'isn', 'your', 'couldn', 'any', \"needn't\", 'further', 'yours', \"you've\", 'it', 'won', 'will', 'weren', 'with', 'but', 'been', 'doesn', \"shan't\", 'her', 'how', 'same', \"doesn't\", \"you'll\", 'below', 'haven', 'on', 'under', 'having', 'you', 'just', 'they', 'mightn', 'has', 'only', 'of', 'this', 'at', \"wouldn't\", 'that', 'ain', 'which', 'wouldn', 'can', 'am', 'such', 'both', 'before', 'what', 've', 'no', 'doing', 'don', 'yourselves', 'have', 'in', 'out', 'is', 'yourself', \"couldn't\", 'who', 'down', 'own', \"haven't\", 'was', 'he', \"you're\", \"hasn't\", 'when', 'after', 'about', 'than', 'hers', \"didn't\", 'we', 'above', 'other', 'too', 'those', 'very', \"it's\", 'hasn', 'y', 'ours', 'herself', 'so', 'them', 'into', 'themselves', 'and', 'mustn', 'these', 'some', 'more', \"you'd\", \"mightn't\", 'do'}\n"
     ]
    }
   ],
   "source": [
    "# we use the list of stop words that are downloaded from nltk lib.\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print ('list of stop words:', stop_words)\n",
    "\n",
    "def nlp_preprocessing(total_text, index, column):\n",
    "    if type(total_text) is not int:\n",
    "        string = \"\"\n",
    "        for words in total_text.split():\n",
    "            # remove the special chars in review like '\"#$@!%^&*()_+-~?>< etc.\n",
    "            word = (\"\".join(e for e in words if e.isalnum()))\n",
    "            # Conver all letters to lower-case\n",
    "            word = word.lower()\n",
    "            # stop-word removal\n",
    "            if not word in stop_words:\n",
    "                string += word + \" \"\n",
    "        data[column][index] = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3156784000002517 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "# we take each title and we text-preprocess it.\n",
    "for index, row in data.iterrows():\n",
    "    nlp_preprocessing(row['title'], index, 'title')\n",
    "# we print the time it took to preprocess whole titles \n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182720</th>\n",
       "      <td>B01GRY940Y</td>\n",
       "      <td>WAYF</td>\n",
       "      <td>Red</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>wayf womens printed splitneck long sleeve blou...</td>\n",
       "      <td>$9.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182725</th>\n",
       "      <td>B01M0CTZL5</td>\n",
       "      <td>Vintage America Blues</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>APPAREL</td>\n",
       "      <td>vintage america womens marissa pintuck embroid...</td>\n",
       "      <td>$12.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182726</th>\n",
       "      <td>B01M1OC0NX</td>\n",
       "      <td>Free People</td>\n",
       "      <td>Black</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>free people peaks island black top large</td>\n",
       "      <td>$59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182737</th>\n",
       "      <td>B000T8GQME</td>\n",
       "      <td>UltraClub</td>\n",
       "      <td>Brick</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>ultraclub ladies cabana breeze camp shir x lar...</td>\n",
       "      <td>$29.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182738</th>\n",
       "      <td>B00139HZFU</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>Nantucket Navy</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>featherlite ladies long sleeve stain resistant...</td>\n",
       "      <td>$22.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182720</th>\n",
       "      <td>B01GRY940Y</td>\n",
       "      <td>WAYF</td>\n",
       "      <td>Red</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>wayf womens printed splitneck long sleeve blou...</td>\n",
       "      <td>$9.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182725</th>\n",
       "      <td>B01M0CTZL5</td>\n",
       "      <td>Vintage America Blues</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>APPAREL</td>\n",
       "      <td>vintage america womens marissa pintuck embroid...</td>\n",
       "      <td>$12.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182726</th>\n",
       "      <td>B01M1OC0NX</td>\n",
       "      <td>Free People</td>\n",
       "      <td>Black</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>free people peaks island black top large</td>\n",
       "      <td>$59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182737</th>\n",
       "      <td>B000T8GQME</td>\n",
       "      <td>UltraClub</td>\n",
       "      <td>Brick</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>ultraclub ladies cabana breeze camp shir x lar...</td>\n",
       "      <td>$29.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182738</th>\n",
       "      <td>B00139HZFU</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>Nantucket Navy</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>featherlite ladies long sleeve stain resistant...</td>\n",
       "      <td>$22.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('pickels/16k_apperal_data_preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argu\nfish\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem('arguing'))\n",
    "print(stemmer.stem('fishing'))\n",
    "\n",
    "\n",
    "# We tried using stemming on our titles and it didnot work very well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
